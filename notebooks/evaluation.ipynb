{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tabulate\n",
    "\n",
    "from train import PATH_LOADERS, ROOT\n",
    "from evaluate.quality import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.HTML('''<script>\n",
    "  code_show=true;\n",
    "  function code_toggle() {\n",
    "    if (code_show){\n",
    "      $('div.input').hide();\n",
    "    } else {\n",
    "      $('div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "  }\n",
    "  $( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Toggle code on/off\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seen data\n",
    "\n",
    "We have four training speakers and test on the same four speakers.\n",
    "\n",
    "**Qualitative results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"grid\"\n",
    "filelist = \"k-seen\"\n",
    "split = \"test\"\n",
    "path_loader = PATH_LOADERS[dataset](ROOT, filelist + \"-\" + split)\n",
    "path_prediction_dict = {\n",
    "    \"k\": \"data/grid/samples-konstantinos/seen\",\n",
    "    \"ours\": \"output/synth-samples/grid-k-seen-test-magnus-best\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    method: {\n",
    "        metric: dict(zip(path_loader.ids, evaluate(metric, path_loader, path_prediction_dict[method])))\n",
    "        for metric in [\"pesq\", \"stoi\"]\n",
    "    }\n",
    "    for method in [\"k\", \"ours\"] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_html(path, sr):\n",
    "    audio, _ = librosa.core.load(path, sr)\n",
    "    display_audio = display.Audio(audio, rate=sr)\n",
    "    return display_audio._repr_html_()\n",
    "\n",
    "def get_row(id1):\n",
    "    filename = path_loader.id_to_filename(id1, \"audio\")\n",
    "    return [\n",
    "        filename,\n",
    "        get_audio_html(os.path.join(path_loader.folders[\"audio\"], filename), 16_000),\n",
    "        get_audio_html(os.path.join(path_prediction_dict[\"ours\"], filename), 16_000),\n",
    "        get_audio_html(os.path.join(path_prediction_dict[\"k\"], filename), 50_000),\n",
    "        results[\"ours\"][\"pesq\"][id1],\n",
    "        results[\"k\"][\"pesq\"][id1],\n",
    "        results[\"ours\"][\"stoi\"][id1],\n",
    "        results[\"k\"][\"stoi\"][id1],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ids = random.sample(path_loader.ids, 16)\n",
    "table = [get_row(i) for i in selected_ids]\n",
    "table = sorted(table, key=lambda t: t[0])\n",
    "headers = [\"filename\", \"groundtruth\", \"ours\", \"k\", \"pesq ↑ ours\", \"pesq ↑ k\", \"stoi ↑ ours\", \"stoi ↑ k\"]\n",
    "display.display(display.HTML(tabulate.tabulate(table, tablefmt='html', headers=headers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantitative results.**\n",
    "\n",
    "Methods:\n",
    "- `K`: the method of Vougioukas _et al._ (Interspeech, 2019)\n",
    "- `B / spk`: baseline model trained independently for each speaker\n",
    "- `B`: baseline model trained on all four speaker at once\n",
    "- `SI`: baseline model augmenented with speaker ID information\n",
    "- `SI + D`: baseline model with speaker ID and dispel branch\n",
    "\n",
    "Notes:\n",
    "- Test data consists of four seen speakers: `s1`, `s2`, `s4`, `s29`\n",
    "- ? For MCD I was not able to achieve comparable to what is in the paper (not even for their method)\n",
    "- ? What kind of FSG should I use for the ASR? Currently forcing six words at the output.\n",
    "\n",
    "| method | STOI ↑ | PESQ ↑ | MCD ↓ | WER ↓ |\n",
    "|--------|--------|--------|-------|-------|\n",
    "| `K` _paper_ | 0.518 | 1.71 | 22.29 | 26.6 |\n",
    "| `K` _recomputed_ | 0.525 | 1.72 | 673.3 | 27.1 |\n",
    "| `B / spk` | 0.452 | 1.82 | 882.7 | 17.8 |\n",
    "| `B` | 0.470 | 1.88 | 882.5 | 21.8 |\n",
    "| `SI` | 0.468 | 1.85 | 864.7 | 19.9 |\n",
    "| `SI + D` | 0.449 | 1.78 | 866.8 | 24.5 |\n",
    "\n",
    "Code to run:\n",
    "\n",
    "```bash\n",
    "# K\n",
    "python evaluate/quality.py -m stoi -d grid --filelist k-seen -p data/grid/samples-konstantinos/seen\n",
    "# B / spk\n",
    "python evaluate/quality.py -m stoi -d grid --filelist k-seen -p output/synth-samples/grid-k-seen-test-magnus-best\n",
    "# B\n",
    "python evaluate/quality.py -m stoi -d grid --filelist k-seen -p output/synth-samples/grid-k-seen-test-magnus-indep-best\n",
    "# SI\n",
    "python evaluate/quality.py -m stoi -d grid --filelist k-seen -p output/synth-samples/grid-k-seen-test-magnus-multi-speaker-best\n",
    "# SI + D\n",
    "python evaluate/quality.py -m stoi -d grid --filelist k-seen -p output/synth-samples/grid-k-seen-test-magnus-multi-speaker-dispel-best\n",
    "\n",
    "# For WER\n",
    "bash scripts/evaluate-seen-wer.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen data\n",
    "\n",
    "- 14 seen speakers and 9 unseen speakers\n",
    "- We use a subset of the samples: 50 samples for each speaker, that is 450 samples\n",
    "- For the methods that rely on speaker identity we use a mean embedding of the speakers seen at train time\n",
    "\n",
    "\n",
    "| method | STOI ↑ | PESQ ↑ | MCD ↓ | WER ↓ |\n",
    "|--------|--------|--------|-------|-------|\n",
    "| `K` _paper_ | 0.445 | 1.24 | 24.29 | 40.5 |\n",
    "| `K` _recomputed_ | 0.449 | 1.24 | 752.5 | 40.1 |\n",
    "| `B` | 0.374 | 1.28 | 896.9 | 36.4 |\n",
    "| `SI` | 0.352 | 1.15 | 883.7 | 39.4 |\n",
    "| `SI + D` | 0.315 | 1.07 | 995.7 | 62.1 |\n",
    "| `SE` | 0.365 | 1.25 | 908.2 | 34.9 |\n",
    "| `SE + D` | 0.359 | 1.17 | 974.3 | 42.3 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qualitative results.**\n",
    "In this section we look at the samples generated for the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"grid\"\n",
    "filelist = \"unseen-k-small\"\n",
    "split = \"test\"\n",
    "path_loader = PATH_LOADERS[dataset](ROOT, filelist + \"-\" + split)\n",
    "path_prediction_dict = {\n",
    "    \"k\": \"data/grid/samples-konstantinos/unseen\",\n",
    "    \"B\": \"output/synth-samples/grid-multi-speaker-unseen-k-small-test-magnus-best\",\n",
    "    \"SI\": \"output/synth-samples/grid-multi-speaker-unseen-k-small-test-magnus-multi-speaker-best-emb-mean\",\n",
    "    \"SI+D\": \"output/synth-samples/grid-multi-speaker-unseen-k-small-test-magnus-multi-speaker-dispel-best-emb-mean\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row(id1):\n",
    "    sr = 16_000\n",
    "    filename = path_loader.id_to_filename(id1, \"audio\")\n",
    "    return [\n",
    "        filename,\n",
    "        get_audio_html(os.path.join(path_loader.folders[\"audio\"], filename), sr),\n",
    "        get_audio_html(os.path.join(path_prediction_dict[\"k\"], filename), 50_000),\n",
    "    ] + [\n",
    "        get_audio_html(os.path.join(path_prediction_dict[method], filename), sr)\n",
    "        for method in \"B SI SI+D\".split()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ids = random.sample(path_loader.ids, 16)\n",
    "table = [get_row(i) for i in selected_ids]\n",
    "table = sorted(table, key=lambda t: t[0])\n",
    "headers = [\"filename\", \"groundtruth\", \"k\", \"B\", \"SI\", \"SI+D\"]\n",
    "display.display(display.HTML(tabulate.tabulate(table, tablefmt='html', headers=headers)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
